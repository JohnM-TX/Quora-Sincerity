{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b2e35a94595b7837b0e297ea70dc3095cd40a9cc"
   },
   "source": [
    "# Drunk Anteaters and Text Classification\n",
    "\n",
    "This kernel demonstrates common techniques for analyzing text data and classifying documents. Examples include:\n",
    "* Assigning categories to notes from call center reps\n",
    "* Finding themes in medical records\n",
    "* Identifying toxic comments on social media\n",
    "\n",
    "The example here is based on [Quora Insincere Questions Classification](https://www.kaggle.com/c/quora-insincere-questions-classification). The goal is to identify questions that may be \"insincere\"(definition to follow).\n",
    "\n",
    "We'll follow this approach to building a useful machine learning model.\n",
    "\n",
    "<img src=\"https://i.imgur.com/M5eC2FT.png\" width=\"700\">\n",
    "\n",
    "\n",
    "--\n",
    "--\n",
    "\n",
    "## Context\n",
    "Quora is one of my favorite sites to visit. You can learn about useful things and also totally useless things. Of coures this is quite different than our objective here, which is to say whether or not a question is sincere. Here's an example - sounds sincere, but is it useful? Not to me since I don't interact with anteaters. I appreciate it just the same and love Quora for these types of questions!\n",
    "\n",
    "<img src=\"https://s4.scoopwhoop.com/anj/cashkaro/27222808.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce28218cc04f8573728074cc21a7dba6f8438f86"
   },
   "source": [
    "Back to the task at hand. From the Data tab of the competition, we have some explanation of what is insincere.\n",
    " \n",
    "> An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:\n",
    "> \n",
    "> * Has a non-neutral tone\n",
    "> * Is disparaging or inflammatory\n",
    "> * Isn't grounded in reality\n",
    "> * Uses sexual content for shock value, and not to seek genuine answers\n",
    "\n",
    "\n",
    "Identifying these characteristics for binary classification can be challenging. Be sure to look at past Kaggle competitions and academic papers for additional resources!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2359d29d2504c43d36c60d59db954551b4ce58c0"
   },
   "source": [
    "## Data Exploration\n",
    "Let's first look at the data in tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a4f4822caaa18b65393b358472b39f8e37cf2c3"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 120)\n",
    "\n",
    "numrows = None #none==all rows\n",
    "train = pd.read_csv('train.csv', index_col=['qid'], nrows=numrows)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5fd50f3e779549426190bf2009e354e7e256d0d1"
   },
   "source": [
    "All zeros? Let's count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ffda743d1a7455e802fb51ad2eac60dc73ccbb6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train.shape[0], \"\\n\",\n",
    "      train.target.value_counts(normalize=\"True\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56a3a21ff0b3c8867966fdef357a2b3a70f0e404"
   },
   "source": [
    "There are many things we can look at for further exploration. Here are a couple of brief examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "78bea369f399ac550e7371839f7ae309eb2ae025"
   },
   "outputs": [],
   "source": [
    "train['qlength'] = train.question_text.str.len()\n",
    "train['why'] = train.question_text.str.startswith(\"Why\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5b74bf22458d6fc377bf4e96acf9c5cdfeb0ef7"
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "\n",
    "display(train.hvplot.kde('qlength', by='target', xlim=(0,500)),\n",
    "        pd.crosstab(train.target, train.why, normalize='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c606df75ddfe61398e573ba09e55487ac52621e"
   },
   "source": [
    "## Pre-process the Data and Generate Features\n",
    "Turning text data into numerical data for consumption by a machine learning model is where the magic comes in. Lucky for us there are now packages that make it easy. \n",
    "\n",
    "\n",
    "#### Preprocessing\n",
    "Most packages have built-in methods for cleaning data. You can specify options that remove puctuation, trim spacing, and remove common words (known as *stop words*). Since social media posts are often defined by these features, we'll leave them in.\n",
    "\n",
    "\n",
    "#### [Sci-kit Learn Count Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf29778737c31dcfa37cbbdd2e0c698c902e83ba"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\")\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "185fe4cfdf690c44b6a10824c754736ceca682cd"
   },
   "source": [
    "#### [Sci-kit Learn Tf-Idf Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)\n",
    "\n",
    "Tf-idf stands for *Term Frequency, Inverse Document Frequency*. It is a way to account for a word's in a document vs. the word's occurrence in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2ae647a0a987acb6b8fecd032622a630abc530e"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\")\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a80cadca100b87e0bcbf2b22c1ec378e1cd0864d"
   },
   "source": [
    "#### Word Embeddings\n",
    "The approaches above are known as *Bag of Words* approaches because the order of words is not considered. Clearly this is a limitation. Newer approaches use *Word Embeddings*. Embeddings are made by mapping vectors and phrases from documents into vectors of numbers. The vectors are the output of deep neural networks trained on large bodies of text. Here is an example of a word embedding known as *GloVe*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ead63fb6061f18df2cda0c04fbb7e96b43d8ca30"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a785558eefee0f945ff4d519f535707ee8ad2e06"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('../input/embeddings/glove.840B.300d/glove.840B.300d.txt', \n",
    "                   header=None, sep=' ', skiprows=2, nrows=5, index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af78638a9a6497af45dd677bfdd9cc137b7476be"
   },
   "source": [
    "These vectors are typically fed into a neural network that uses Keras/Tensorflow or Pytorch. You can also use embeddings in standard machine learning methods such as logistic regression. The most accurate models usually come from word embeddings and deep learning.\n",
    "\n",
    "\n",
    "#### Other Approaches and Packages\n",
    "* spaCy - many features like part-of-speech, word dependencies, others\n",
    "* NLTK - Natural Language Tool Kit with many features\n",
    "* sklearn Latent Dirichlet Allocation - an implementation of [Topic Modeling](https://en.wikipedia.org/wiki/Topic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22cde0dbde3ac013236947aacb3f0d394adf80a1"
   },
   "source": [
    "## Feature Generation and Feature Selection\n",
    "You can add metafeatures such as those seen above in EDA. Sometimes they help. For feature selection, we'll limit the words analyzed to the most common words as part of building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68af29d8294a5587d57186c2c0d98a8174f94d15"
   },
   "source": [
    "## The Classification Model\n",
    "Logistic Regression is a good choice when trying to balance speed and accuracy. This model uses Tf-idf features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67f213049362781a00f6d77cdc960d129cbc506b"
   },
   "outputs": [],
   "source": [
    "#%% get libraries and data\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "numrows = None\n",
    "train = pd.read_csv('../input/train.csv', index_col=['qid'], nrows=numrows)\n",
    "test = pd.read_csv('../input/test.csv', index_col=['qid'], nrows=numrows)\n",
    "y = train.target.values\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb5c3ccd787313f48c0cc9e3195dc1dc1c831ece"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#%% make word vectors\n",
    "word_vectorizer = TfidfVectorizer(ngram_range=(1,2),\n",
    "                                    min_df=3,\n",
    "                                    max_df=0.9,\n",
    "                                    token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\",\n",
    "                                    max_features=50_000,  #basic feature selection\n",
    "                                    strip_accents='unicode',\n",
    "                                    use_idf=True,\n",
    "                                    smooth_idf=True,\n",
    "                                    sublinear_tf=True)\n",
    "\n",
    "print(\"tokenizing\")\n",
    "word_vectorizer.fit(pd.concat((train['question_text'], test['question_text'])))\n",
    "X = word_vectorizer.transform(train['question_text'])\n",
    "X_test = word_vectorizer.transform(test['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "a42e90e2af24688b40b65f9ee69e158ef25aeedb"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#%% split out validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=99, stratify=y)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='saga', class_weight='balanced', \n",
    "                                C=0.5, max_iter=350, n_jobs=2, verbose=1) #seed not set\n",
    "model.fit(X_train, y_train)\n",
    "val_pred = model.predict_proba(X_val)\n",
    "val_pred[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "307b7c7a5cbf83d544e869414b466f72d7fd4f64"
   },
   "source": [
    "## Evaluate\n",
    "The host client wants the predictions in binary format rather than probabilities. The model we built will predict binaries but it sets the threshold at a specific number. We can do better if we try a range of numbers and choose the best cutoff.\n",
    "\n",
    "The score used to evaluate results is the F1 score. It's known to be effective for data sets imbalanced by a dominant class, in this case the 0 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "0a6eef8c1bf9395fa70e0dde1b7520692fe807a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#%% find best threshold\n",
    "def thresh_search(y_true, y_proba):\n",
    "    best_thresh = 0\n",
    "    best_score = 0\n",
    "    for thresh in np.arange(0, 1, 0.1):\n",
    "        score = f1_score(y_true, y_proba > thresh)\n",
    "        if score > best_score:\n",
    "            best_thresh = thresh\n",
    "            best_score = score\n",
    "        print(thresh, score)\n",
    "    return best_thresh, best_score\n",
    "\n",
    "thresh, search = thresh_search(y_val, val_pred[:, 1])\n",
    "print(\"\\n\", thresh, search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "556943a36261fc69e42a7724931839a7a30dc6c6"
   },
   "outputs": [],
   "source": [
    "# submit\n",
    "test_pred = model.predict_proba(X_test)[:,1]\n",
    "sub = pd.read_csv('../input/sample_submission.csv', index_col=['qid'], nrows=numrows)\n",
    "sub['prediction'] = test_pred > thresh\n",
    "sub.to_csv(\"submission.csv\")\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "881f4d8d0659fe5494c7cfee80495de95743c22e"
   },
   "source": [
    "That's it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyslim]",
   "language": "python",
   "name": "conda-env-pyslim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
